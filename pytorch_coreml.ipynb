{
 "cells": [
  {
   "source": [
    "# Add some code on ops.py\n",
    " on \"coremltools/converters/mil/frontend/torch/ops.py\" file, add some code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_torch_op\n",
    "def dim(context, node):\n",
    "    inputs = _get_inputs(context, node)\n",
    "    shape_node = mb.shape(x=inputs[0], name = node.name)\n",
    "\n",
    "    context.add(shape_node)"
   ]
  },
  {
   "source": [
    "# Case 1. Simple Model Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Create Torch Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleTest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleTest, self).__init__()\n",
    "        self.fc1 = nn.Linear(400, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "simple_model = SimpleTest()\n",
    "\n",
    "print(simple_model)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Script to model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "scripted_model = torch.jit.script(simple_model)\n",
    "mlmodel = coremltools.converters.convert(scripted_model, inputs=[coremltools.TensorType(shape=(400,))])\n"
   ]
  },
  {
   "source": [
    "## Trace to model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "simple_model.eval()\n",
    "\n",
    "example_input = torch.rand(400)\n",
    "output = simple_model(example_input)\n",
    "\n",
    "trace = torch.jit.trace(simple_model, example_input)\n",
    "\n",
    "mlmodel = coremltools.convert(trace, source= 'pytorch', inputs=[coremltools.TensorType(name=\"input\", shape=example_input.shape)])\n"
   ]
  },
  {
   "source": [
    "## Save ML Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('simple_model_1.mlmodel')\n"
   ]
  },
  {
   "source": [
    "# Case 2. Simple Model Test 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1614910244952,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "DASLqPHSFJmb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple layer module we'll reuse in our network.\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(Layer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(*dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1614910247313,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "nixpAvZrGtZ4"
   },
   "outputs": [],
   "source": [
    "# A simple network consisting of several base layers.\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = Layer((3, 6, 1))\n",
    "        self.layer2 = Layer((6, 16, 1))\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGqvumtKG5dB"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "model.eval()\n",
    "\n",
    "traceable_model = model\n",
    "example_input = torch.rand(1,3,20,20)\n",
    "output = model(example_input)\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "trace = torch.jit.trace(traceable_model, example_input)\n",
    "\n",
    "# print(trace)\n",
    "\n",
    "mlmodel = coremltools.convert(trace, source= 'pytorch', inputs=[coremltools.TensorType(name=\"xyz\", shape=example_input.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('test3.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjXNKquCIYfy"
   },
   "source": [
    "# Case 3. MNIST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esVXUXVQIutT"
   },
   "source": [
    "## import needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1614936348454,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "R0Tzh1WxIhaR"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWfAueb-IykX"
   },
   "source": [
    "## make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1614936349696,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "UQ6va0wgItTx",
    "outputId": "f30fe175-bb6f-4bf7-fffa-f1972c9ed863"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "# LeNet\n",
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    # 입력 이미지 채널 1개, 출력 채널 6개, 3x3의 정사각 컨볼루션 행렬\n",
    "    # 컨볼루션 커널 정의\n",
    "    self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "    # 아핀(affine) 연산 : y = Wx + b\n",
    "    self.fc1 = nn.Linear(16 * 6 * 6, 120) # 6*6은 이미지 차원\n",
    "    # self.fc1 = nn.Linear(576, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    # self.showshape = True\n",
    "\n",
    "  def forward(self, x):\n",
    "    # (2, 2) 크기 윈도우에 대해 맥스 풀링(max pooling)\n",
    "    #input 28x28 >> after conv 6@26x26 >> max pooling 6@13x13\n",
    "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "    # 크기가 제곱수라면 하나의 숫자만을 특정\n",
    "    #input 6@13x13 >> after conv 16@11x11 >> max pooling 16@5x5\n",
    "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "    # x = x.view(-1, self.num_flat_features(x))\n",
    "    x = x.view(-1, 576)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "  \n",
    "  def num_flat_features(self, x):\n",
    "    #print(x.size())\n",
    "    size = x.size()[1:]\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "      num_features *= s\n",
    "    #print(num_features)\n",
    "    return num_features\n",
    "\n",
    "net = Net()#.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAQsrF2gUHXO"
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1614932481926,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "mZPJmw5XUJWY"
   },
   "outputs": [],
   "source": [
    "torch.save(net, './nntest.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F3KCHJhJZC-"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1614936354051,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "6K_4LyNNJeDV"
   },
   "outputs": [],
   "source": [
    "net = torch.load('./nntest.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlPivgboI2xh"
   },
   "source": [
    "## Load MNIST datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1614936357047,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "PnjbINCsJB1b"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Normalize data with mean=0.5, std=1.0\n",
    "mnist_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "download_root = './MNIST_DATASET'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# option 값 정의\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xai390LMSunv"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225603,
     "status": "ok",
     "timestamp": 1614932473087,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "rX7kUk_SSwlk",
    "outputId": "663d6044-261a-4507-f4eb-b72fce4bd5a8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "net.train()\n",
    "\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "  for data, target in train_loader:\n",
    "\n",
    "    #data = data.to(device)\n",
    "    #target = target.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr = 0.02)\n",
    "    optimizer.zero_grad()\n",
    "    output = net(data)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward() # calc gradients\n",
    "    train_loss.append(loss.data)\n",
    "    optimizer.step() # update gradients\n",
    "    prediction = output.data.max(1)[1]\n",
    "    accuracy = prediction.eq(target.data).sum() / batch_size * 100\n",
    "    train_accu.append(accuracy)\n",
    "    if i % 1000 == 0:\n",
    "      print(f'Train Step: {i}\\tLoss: {loss.data}\\tAccuracy: {accuracy}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obrfNIEuJnXr"
   },
   "source": [
    "## Check loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1914,
     "status": "ok",
     "timestamp": 1614936364410,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "Dg4-EpmxJqpF",
    "outputId": "d238efd7-20fb-48b9-df51-f388dc139ca6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 0.0006188311381265521\tAccuracy: 98.3499984741211\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "count = 0\n",
    "accuracy = 0.0\n",
    "for data, target in test_loader:#valid_loader:\n",
    "  #print(data.shape)\n",
    "  #print(target.shape)\n",
    "  #data, target = data.to(device), target.to(device)\n",
    "  output = net(data)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  loss = criterion(output, target)\n",
    "  prediction = output.data.max(1)[1]\n",
    "  accuracy += prediction.eq(target.data).sum()\n",
    "  count += prediction.shape[0]\n",
    "accuracy = accuracy / count * 100\n",
    "print(f'Loss: {loss.data}\\tAccuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKchY5tzKFJM"
   },
   "source": [
    "## Convert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1614929831126,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "l5oSqhU1KH6n",
    "outputId": "59e32f85-fd7e-4960-bc1c-f543f0be72a9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28])\ntorch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# print(data.shape)\n",
    "input_tensor = mnist_transform(data[0][0].numpy())\n",
    "print(input_tensor.shape)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "print(input_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 990,
     "status": "error",
     "timestamp": 1614936366774,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "m3rjZN6IMJzk",
    "outputId": "91d6ecb1-b086-418a-8498-e9f3b8eebb68"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Converting Frontend ==> MIL Ops:  98%|█████████▊| 58/59 [00:00<00:00, 1953.06 ops/s]\n",
      "Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 624.04 passes/s]\n",
      "Translating MIL ==> MLModel Ops: 100%|██████████| 41/41 [00:00<00:00, 2144.81 ops/s]11 constant\n",
      "12 constant\n",
      "13 constant\n",
      "14 constant\n",
      "15 listconstruct\n",
      "16 listconstruct\n",
      "17 listconstruct\n",
      "18 listconstruct\n",
      "input.2 _convolution\n",
      "input.3 relu\n",
      "21 constant\n",
      "22 constant\n",
      "23 listconstruct\n",
      "24 listconstruct\n",
      "25 constant\n",
      "26 constant\n",
      "27 listconstruct\n",
      "28 constant\n",
      "29 constant\n",
      "30 listconstruct\n",
      "31 constant\n",
      "input.4 max_pool2d\n",
      "33 constant\n",
      "34 constant\n",
      "35 constant\n",
      "36 constant\n",
      "37 listconstruct\n",
      "38 listconstruct\n",
      "39 listconstruct\n",
      "40 listconstruct\n",
      "input.5 _convolution\n",
      "input.6 relu\n",
      "43 constant\n",
      "44 constant\n",
      "45 listconstruct\n",
      "46 listconstruct\n",
      "47 constant\n",
      "48 constant\n",
      "49 listconstruct\n",
      "50 constant\n",
      "51 constant\n",
      "52 listconstruct\n",
      "53 constant\n",
      "x max_pool2d\n",
      "55 constant\n",
      "56 constant\n",
      "57 listconstruct\n",
      "input.7 view\n",
      "59 constant\n",
      "60 t\n",
      "input.8 addmm\n",
      "input.9 relu\n",
      "63 constant\n",
      "64 t\n",
      "input.10 addmm\n",
      "input relu\n",
      "67 constant\n",
      "68 t\n",
      "69 addmm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "net.eval()\n",
    "traceable_model = net\n",
    "# example_input = torch.rand(1,1,28,28)\n",
    "trace = torch.jit.trace(traceable_model, input_batch)\n",
    "\n",
    "# print(trace)\n",
    "\n",
    "mlmodel = coremltools.convert(trace, source= 'pytorch', inputs=[coremltools.TensorType(name=\"image_input\", shape=input_batch.shape)])\n",
    "\n",
    "# mlmodel = coremltools.convert(\"nntest.pt\", source= 'pytorch', inputs=[coremltools.TensorType(name=\"input\", shape=(1,1,28,28))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM3i-mNsF3uE"
   },
   "source": [
    "## from model script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "error",
     "timestamp": 1614926086110,
     "user": {
      "displayName": "이창영",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifHya3DVvt1wScxz-dJV-GWW6_A4j_3lab1ZShMA=s64",
      "userId": "00737351585679405989"
     },
     "user_tz": -540
    },
    "id": "KdAswRCpF8rH",
    "outputId": "7fd4a3a0-4d3e-4071-e45b-629cdc02cd15"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Converting Frontend ==> MIL Ops:   0%|          | 0/53 [00:00<?, ? ops/s]\n",
      "Converting Frontend ==> MIL Ops:   0%|          | 0/1 [00:00<?, ? ops/s]\n",
      "\n",
      "Converting Frontend ==> MIL Ops:   0%|          | 0/1 [00:00<?, ? ops/s]\n",
      "Converting Frontend ==> MIL Ops:  32%|███▏      | 17/53 [00:00<00:00, 1464.25 ops/s]\n",
      "11 constant\n",
      "12 constant\n",
      "13 constant\n",
      "14 constant\n",
      "15 constant\n",
      "16 constant\n",
      "17 constant\n",
      "18 constant\n",
      "19 listconstruct\n",
      "20 listconstruct\n",
      "21 listconstruct\n",
      "22 conv2d\n",
      "result.3 if\n",
      "result.4 relu_\n",
      "result.5 relu\n",
      "26 listconstruct\n",
      "27 listconstruct\n",
      "28 listconstruct\n",
      "29 constant\n",
      "30 __is__\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "PyTorch convert function for op '__is__' not implemented.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e327755281a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m mlmodel = coremltools.converters.convert(\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mscripted_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         **kwargs)\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     mlmodel = mil_convert(\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mconvert_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     proto = mil_convert_to_proto(model, convert_from, convert_to,\n\u001b[0m\u001b[1;32m    129\u001b[0m         ConverterRegistry, **kwargs)\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mil'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mfrontend_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mcommon_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the following model ops are MISSING:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"  \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"convert function\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;31m# Add the rest of the operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mconvert_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mgraph_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/ops.py\u001b[0m in \u001b[0;36mconvert_nodes\u001b[0;34m(context, graph)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converting op {} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_add_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0;34m\"PyTorch convert function for op '{}' not implemented.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PyTorch convert function for op '__is__' not implemented."
     ]
    }
   ],
   "source": [
    "#model = ControlFlowNet(num_channels=3)\n",
    "scripted_model = torch.jit.script(net)\n",
    "\n",
    "import coremltools\n",
    "mlmodel = coremltools.converters.convert(\n",
    "  scripted_model,\n",
    "  inputs=[coremltools.TensorType(shape=(1, 1, 28, 28))],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS2fM2f7NINN"
   },
   "source": [
    "## save ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FLd7T5GwNLVz"
   },
   "outputs": [],
   "source": [
    "mlmodel.save(\"mnist_traced.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "h6buKPNkOAj7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load the model\n",
    "mlmodel = coremltools.models.MLModel(\"mnist_traced.mlmodel\")\n",
    "\n",
    "labels_json = {\"labels\": [0,1,2,3,4,5,6,7,8,9]}\n",
    "\n",
    "mlmodel.user_defined_metadata[\"com.apple.coreml.model.preview.type\"] = \"MNIST\"\n",
    "mlmodel.user_defined_metadata['com.apple.coreml.model.preview.params'] = json.dumps(labels_json)\n",
    "\n",
    "mlmodel.save(\"mnist_traced.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP5Mtm83rnm54DLw6io25f6",
   "collapsed_sections": [],
   "name": "pytorch_coreml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch_env': conda)",
   "language": "python",
   "name": "python38864bitpytorchenvcondafbf08df0972049c0a396d40f2e796ea9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}